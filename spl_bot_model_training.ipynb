{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ebf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from spl_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a1e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7eff810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 647\n"
     ]
    }
   ],
   "source": [
    "print(data.min(), data.max()) # so we know what vocab size we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f2ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#had some issue with cude device, so used only cpu\n",
    "\n",
    "device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type = 'cpu' #'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46ab818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 191.55K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(648, 64)\n",
       "    (wpe): Embedding(64, 64)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-2): 3 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=64, out_features=192, bias=True)\n",
       "          (c_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=64, out_features=648, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GPTConfig:\n",
    "    block_size: int = 64\n",
    "    lineup_size: int = 7\n",
    "    vocab_size: int = 648 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 3\n",
    "    n_head: int = 1\n",
    "    n_rules: int = 57\n",
    "    n_embd: int = 64\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "gptconf = GPTConfig()\n",
    "\n",
    "model = GPT(gptconf)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e567b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('spl_bot_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbafb2",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3fc95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after about 20k steps the model improvement was slow\n",
    "\n",
    "max_iters = 50000\n",
    "learning_rate = 1e-3\n",
    "eval_interval = 2000\n",
    "batch_size = 64\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    x0, x1, y = get_batch(data, batch_size, gptconf.n_embd, gptconf.lineup_size, device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(x0, x1, y)\n",
    "    \n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        print(f\"step {iter}: train loss {loss:.4f}\")\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fc091",
   "metadata": {},
   "source": [
    "## Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010a09e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[437, 388, 384, 385, 337, 520, 391],\n",
       "        [442, 436, 542, 433, 514, 336, 380],\n",
       "        [442, 343, 455, 414, 457, 415, 346],\n",
       "        [437, 388, 384, 339, 390, 385, 516],\n",
       "        [442, 348, 450, 433, 371, 457, 512],\n",
       "        [442, 343, 455, 411, 414, 555, 346],\n",
       "        [437, 388, 384, 390, 519, 385, 520]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, x1, y = get_batch(data, 1, gptconf.n_embd, gptconf.lineup_size, device, generate=True)\n",
    "\n",
    "#generated outputs\n",
    "idx = model.generate(x0, x1, max_new_tokens=7, top_k=3)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c43bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "437     Kelya Frendul\n",
      "388       Diemonshark\n",
      "384      Flying Squid\n",
      "385        Deeplurker\n",
      "337    Pelacor Bandit\n",
      "520     Swamp Spitter\n",
      "391        Wave Brood\n",
      "Name: name, dtype: object\n",
      "id\n",
      "442    Quix the Devious\n",
      "436         Void Dragon\n",
      "542     Venari Marksrat\n",
      "433        Chaos Dragon\n",
      "514      Fungus Flinger\n",
      "336        Djinn Biljka\n",
      "380        Fungus Fiend\n",
      "Name: name, dtype: object\n",
      "id\n",
      "442       Quix the Devious\n",
      "343       Pelacor Conjurer\n",
      "455               Vulguine\n",
      "414        Celestial Harpy\n",
      "457    Dhampir Infiltrator\n",
      "415              Time Mage\n",
      "346          Naga Assassin\n",
      "Name: name, dtype: object\n",
      "id\n",
      "437      Kelya Frendul\n",
      "388        Diemonshark\n",
      "384       Flying Squid\n",
      "339     Djinn Oshannus\n",
      "390    Nerissa Tridawn\n",
      "385         Deeplurker\n",
      "516    Kulu Mastermind\n",
      "Name: name, dtype: object\n",
      "id\n",
      "442       Quix the Devious\n",
      "348           Djinn Chwala\n",
      "450          Carnage Titan\n",
      "433           Chaos Dragon\n",
      "371         Goblin Psychic\n",
      "457    Dhampir Infiltrator\n",
      "512          Thane Newsong\n",
      "Name: name, dtype: object\n",
      "id\n",
      "442    Quix the Devious\n",
      "343    Pelacor Conjurer\n",
      "455            Vulguine\n",
      "411        Stitch Leech\n",
      "414     Celestial Harpy\n",
      "555                Vruz\n",
      "346       Naga Assassin\n",
      "Name: name, dtype: object\n",
      "id\n",
      "437        Kelya Frendul\n",
      "388          Diemonshark\n",
      "384         Flying Squid\n",
      "390      Nerissa Tridawn\n",
      "519    Riverboat Captain\n",
      "385           Deeplurker\n",
      "520        Swamp Spitter\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cards_df = get_all_cards()['name']\n",
    "\n",
    "#adding extra name for empty slot in lineups\n",
    "cards_df.loc[0] = 'none'\n",
    "\n",
    "f = lambda x: cards_df.loc[x]\n",
    "\n",
    "for i in idx.numpy():\n",
    "    print(f(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ef91c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{240: 308,\n",
       " 437: 33173,\n",
       " 438: 12322,\n",
       " 439: 9310,\n",
       " 440: 7723,\n",
       " 441: 7077,\n",
       " 442: 24705,\n",
       " 463: 5539,\n",
       " 464: 3583,\n",
       " 502: 1383,\n",
       " 506: 4553,\n",
       " 507: 8123,\n",
       " 509: 6489,\n",
       " 547: 866,\n",
       " 548: 309,\n",
       " 549: 3435,\n",
       " 550: 1312,\n",
       " 551: 2339,\n",
       " 552: 3873,\n",
       " 553: 2436,\n",
       " 554: 2178,\n",
       " 637: 167,\n",
       " 638: 148,\n",
       " 639: 215,\n",
       " 640: 203,\n",
       " 641: 116,\n",
       " 642: 119,\n",
       " 644: 279,\n",
       " 645: 209,\n",
       " 647: 278}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model often returns summoners 437 and 442 because they are most common in training data\n",
    "unique, counts = np.unique(data[:,0,-7], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269b0f5",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'spl_bot_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
